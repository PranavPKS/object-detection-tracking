{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# Real-time Multi-object detection and tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "from multiprocessing import Queue, Pool\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5FNuiRPWKMN"
   },
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bm0_uNRnWKMN",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranavpks/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "from session_worker import SessionWorker\n",
    "from webcam_stream import WebcamVideoStream\n",
    "from FPS_helper import FPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_sEBLpVWKMQ"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "VyPz_t8WWKMQ"
   },
   "outputs": [],
   "source": [
    "#MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "MODEL_NAME = 'ssd_mobilenet_v11'\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Session Config: allow seperate GPU/CPU adressing and limit memory allocation\n",
    "_tf_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "_tf_config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frozen model into memory...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def load_frozenmodel():\n",
    "    \n",
    "    print('Loading frozen model into memory...')\n",
    "    \n",
    "    def _node_name(n):\n",
    "        if n.startswith(\"^\"):\n",
    "            return n[1:]\n",
    "        else:\n",
    "            return n.split(\":\")[0]\n",
    "  \n",
    "    # load a frozen Model and split it into GPU and CPU graphs\n",
    "    # this is Hardcoded for ssd_mobilenet only\n",
    "    input_graph = tf.Graph()\n",
    "    with tf.Session(graph=input_graph):\n",
    "        if ssd_shape == 600:\n",
    "            shape = 7326\n",
    "        else:\n",
    "            shape = 1917\n",
    "            \n",
    "        score = tf.placeholder(tf.float32, shape=(None, shape, NUM_CLASSES), name=\"Postprocessor/convert_scores\")\n",
    "        expand = tf.placeholder(tf.float32, shape=(None, shape, 1, 4), name=\"Postprocessor/ExpandDims_1\")\n",
    "        \n",
    "        for node in input_graph.as_graph_def().node:\n",
    "            if node.name == \"Postprocessor/convert_scores\":\n",
    "                score_def = node\n",
    "            if node.name == \"Postprocessor/ExpandDims_1\":\n",
    "                expand_def = node\n",
    "\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            dest_nodes = ['Postprocessor/convert_scores','Postprocessor/ExpandDims_1']\n",
    "\n",
    "            edges = {}\n",
    "            name_to_node_map = {}\n",
    "            node_seq = {}\n",
    "            seq = 0\n",
    "            for node in od_graph_def.node:\n",
    "                n = _node_name(node.name)\n",
    "                name_to_node_map[n] = node\n",
    "                edges[n] = [_node_name(x) for x in node.input]\n",
    "                node_seq[n] = seq\n",
    "                seq += 1\n",
    "            for d in dest_nodes:\n",
    "                assert d in name_to_node_map, \"%s is not in graph\" % d\n",
    "\n",
    "            nodes_to_keep = set()\n",
    "            next_to_visit = dest_nodes[:]\n",
    "\n",
    "            while next_to_visit:\n",
    "                n = next_to_visit[0]\n",
    "                del next_to_visit[0]\n",
    "                if n in nodes_to_keep: continue\n",
    "                nodes_to_keep.add(n)\n",
    "                next_to_visit += edges[n]\n",
    "\n",
    "            nodes_to_keep_list = sorted(list(nodes_to_keep), key=lambda n: node_seq[n])\n",
    "            nodes_to_remove = set()\n",
    "\n",
    "            for n in node_seq:\n",
    "                if n in nodes_to_keep_list: continue\n",
    "                nodes_to_remove.add(n)\n",
    "            nodes_to_remove_list = sorted(list(nodes_to_remove), key=lambda n: node_seq[n])\n",
    "\n",
    "            keep = graph_pb2.GraphDef()\n",
    "            for n in nodes_to_keep_list:\n",
    "                keep.node.extend([copy.deepcopy(name_to_node_map[n])])\n",
    "\n",
    "            remove = graph_pb2.GraphDef()\n",
    "            remove.node.extend([score_def])\n",
    "            remove.node.extend([expand_def])\n",
    "            for n in nodes_to_remove_list:\n",
    "                remove.node.extend([copy.deepcopy(name_to_node_map[n])])\n",
    "\n",
    "            with tf.device('/gpu:0'):\n",
    "                tf.import_graph_def(keep, name='')\n",
    "            with tf.device('/cpu:0'):\n",
    "                tf.import_graph_def(remove, name='')\n",
    "        \n",
    "        print(\"Done!\")\n",
    "        \n",
    "        return detection_graph, score, expand\n",
    "\n",
    "ssd_shape = 300\n",
    "graph, score, expand = load_frozenmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_detect2track(box, width, height):\n",
    "    # transforms normalized to absolut coordinates\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    ymin = ymin*height\n",
    "    xmin = xmin*width\n",
    "    ymax = ymax*height\n",
    "    xmax = xmax*width\n",
    "    boxwidth= xmax - xmin\n",
    "    boxheight = ymax - ymin\n",
    "    \n",
    "    newbox = [xmin,ymin, boxwidth, boxheight]\n",
    "    #newbox = map(int,newbox)\n",
    "    return newbox\n",
    "\n",
    "def conv_track2detect(box, width, height):\n",
    "    # transforms absolut to normalized coordinates\n",
    "    dw = 1./width\n",
    "    dh = 1./height\n",
    "    x, y, boxwidth, boxheight = box #map(float,box)\n",
    "    xmin = x * dw\n",
    "    ymin = y * dh\n",
    "    xmax = (x+boxwidth) * dw\n",
    "    ymax = (y+boxheight) * dh\n",
    "    \n",
    "    newbox = np.array([ymin,xmin,ymax,xmax])\n",
    "    return newbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vis_image(image, boxes, classes, scores, category_index, fps, visualize=False, det_interval=5, det_th=0.5, max_frames=500):\n",
    "    if visualize:\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        boxes, \n",
    "        classes, \n",
    "        scores,\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=3,\n",
    "        min_score_thresh=.5)\n",
    "        \n",
    "        if fps:\n",
    "            cv2.putText(image,\"fps: {}\".format(fps.fps_local()), (10,30),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (77, 255, 9), 2)\n",
    "        cv2.imshow('object_detection', image)\n",
    "        \n",
    "    elif not visualize and fps:\n",
    "        # Exit after max frames if no visualization\n",
    "        for box, score, _class in zip(boxes, scores, classes):\n",
    "            if fps._glob_numFrames %det_interval==0 and score > det_th:\n",
    "                label = category_index[_class]['name']\n",
    "                print(\"label: {}\\nscore: {}\\nbox: {}\".format(label, score, box))\n",
    "    \n",
    "    # Exit Option\n",
    "    if visualize:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            return False\n",
    "    elif not visualize and fps:\n",
    "        if fps._glob_numFrames >= max_frames:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the Graph..\n",
      "Start video stream with shape: 640,480\n",
      "(Press 'q' to Exit)\n",
      "Starting the Detection..\n",
      "> FPS: 0.1\n",
      "> FPS: 61.5\n",
      "> FPS: 52.9\n",
      "> FPS: 53.8\n",
      "> FPS: 50.5\n",
      "> [INFO] elapsed time (total): 30.44\n",
      "> [INFO] approx. FPS: 41.07\n"
     ]
    }
   ],
   "source": [
    "#Params\n",
    "video_input         = 0\n",
    "visualize           = True\n",
    "vis_text            = True\n",
    "max_frames          = 500\n",
    "width               = 600\n",
    "height              = 600\n",
    "fps_interval        = 5\n",
    "det_interval        = max_frames//10\n",
    "det_th              = 0.5\n",
    "\n",
    "\n",
    "def detection(detection_graph, category_index, score, expand):\n",
    "    \n",
    "    import sys\n",
    "    sys.path.append(os.getcwd()+'/KCFpy')\n",
    "    import kcftracker\n",
    "    tracker = kcftracker.KCFTracker(False, True, False)\n",
    "    tracker_counter = 0\n",
    "    track = False\n",
    "    \n",
    "    print(\"Building the Graph..\")\n",
    "    \n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph,config=_tf_config) as sess:\n",
    "            # Define Input and Ouput tensors\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            \n",
    "            score_out = detection_graph.get_tensor_by_name('Postprocessor/convert_scores:0')\n",
    "            expand_out = detection_graph.get_tensor_by_name('Postprocessor/ExpandDims_1:0')\n",
    "            score_in = detection_graph.get_tensor_by_name('Postprocessor/convert_scores_1:0')\n",
    "            expand_in = detection_graph.get_tensor_by_name('Postprocessor/ExpandDims_1_1:0')\n",
    "            \n",
    "            # Threading\n",
    "            gpu_worker = SessionWorker(\"GPU\",detection_graph,_tf_config)\n",
    "            cpu_worker = SessionWorker(\"CPU\",detection_graph,_tf_config)\n",
    "            gpu_opts = [score_out, expand_out]\n",
    "            cpu_opts = [detection_boxes, detection_scores, detection_classes, num_detections]\n",
    "            gpu_counter = 0\n",
    "            cpu_counter = 0\n",
    "            \n",
    "            # Start Video Stream and FPS calculation\n",
    "            fps = FPS(fps_interval).start()\n",
    "            vs = WebcamVideoStream(video_input,width,height).start()\n",
    "            \n",
    "            print(\"Starting the Detection..\")\n",
    "            \n",
    "            while vs.isActive():\n",
    "                if not track:\n",
    "                    # split model in seperate gpu and cpu session threads\n",
    "                    if gpu_worker.is_sess_empty():\n",
    "                        # read video frame, expand dimensions and convert to rgb\n",
    "                        image = vs.read()\n",
    "\n",
    "                        image_expanded = np.expand_dims(image, axis=0)\n",
    "                        # put new queue\n",
    "                        gpu_feeds = {image_tensor: image_expanded}\n",
    "                        if visualize:\n",
    "                            gpu_extras = image # for visualization frame\n",
    "                        else:\n",
    "                            gpu_extras = None\n",
    "                        gpu_worker.put_sess_queue(gpu_opts,gpu_feeds,gpu_extras)\n",
    "\n",
    "                    g = gpu_worker.get_result_queue()\n",
    "\n",
    "                    if g is None:\n",
    "                        # gpu thread has no output queue. ok skip, let's check cpu thread.\n",
    "                        gpu_counter += 1\n",
    "\n",
    "                    else:\n",
    "                        # gpu thread has output queue.\n",
    "                        gpu_counter = 0\n",
    "                        score,expand,image = g[\"results\"][0],g[\"results\"][1],g[\"extras\"]\n",
    "\n",
    "                        if cpu_worker.is_sess_empty():\n",
    "                            # When cpu thread has no next queue, put new queue.\n",
    "                            # else, drop gpu queue.\n",
    "                            cpu_feeds = {score_in: score, expand_in: expand}\n",
    "                            cpu_extras = image\n",
    "                            cpu_worker.put_sess_queue(cpu_opts,cpu_feeds,cpu_extras)\n",
    "\n",
    "                    c = cpu_worker.get_result_queue()\n",
    "                    if c is None:\n",
    "                        # cpu thread has no output queue. ok, nothing to do. continue\n",
    "                        cpu_counter += 1\n",
    "                        time.sleep(0.005)\n",
    "                        continue # If CPU RESULT has not been set yet, no fps update\n",
    "\n",
    "                    else:\n",
    "                        cpu_counter = 0\n",
    "                        boxes, scores, classes, num, image = c[\"results\"][0],c[\"results\"][1],c[\"results\"][2],c[\"results\"][3],c[\"extras\"]\n",
    "                    \n",
    "                    boxes, classes, scores = np.squeeze(boxes),np.squeeze(classes).astype(np.int32),np.squeeze(scores)\n",
    "                    vis = vis_image(image, boxes, classes, scores, category_index, fps,\n",
    "                                        visualize, det_interval, det_th, max_frames)\n",
    "                    if not vis:\n",
    "                        break\n",
    "                        \n",
    "                    \n",
    "                    # Activate Tracker\n",
    "                    if num <= 5: # Max number of objects to track\n",
    "                        tracker_frame = image\n",
    "                        track = True\n",
    "                        first_track = True\n",
    "                \n",
    "                # Tracking\n",
    "                else:\n",
    "                    frame = vs.read()\n",
    "\n",
    "                    if first_track:\n",
    "                        trackers = []\n",
    "                        tracker_boxes = boxes\n",
    "                        for box in boxes[~np.all(boxes == 0, axis=1)]:\n",
    "                                tracker.init(conv_detect2track(box,vs.real_width, vs.real_height), tracker_frame)\n",
    "                                trackers.append(tracker)\n",
    "                        first_track = False\n",
    "\n",
    "                    for idx,tracker in enumerate(trackers):\n",
    "                        tracker_box = tracker.update(frame)\n",
    "                        tracker_boxes[idx,:] = conv_track2detect(tracker_box, vs.real_width, vs.real_height)\n",
    "\n",
    "                    vis = vis_image(image, boxes, classes, scores, category_index, fps,\n",
    "                                        visualize, det_interval, det_th, max_frames)\n",
    "                    if not vis:\n",
    "                        break\n",
    "\n",
    "                    tracker_counter += 1\n",
    "                    if tracker_counter >= 20: #Number of tracked frames between detections\n",
    "                        track = False\n",
    "                        tracker_counter = 0\n",
    "\n",
    "                \n",
    "                fps.update()\n",
    "\n",
    "   \n",
    "    gpu_worker.stop()\n",
    "    cpu_worker.stop()\n",
    "    fps.stop()\n",
    "    vs.stop()\n",
    "\n",
    "\n",
    "detection(graph, category_index, score, expand)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
